[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/gSldEXG6)
# Welcome to 11팀

## 1️⃣ 팀원 소개

| **이름** | **전공** | **관심사** |
| --- | --- | --- |
| **김현수** | 인공지능전공 | 인공지능, 프론트 엔드, 디자인|
| **이소후** | 인공지능전공 | 웹 개발, 춤 |
| **홍진선** | 인공지능전공 | 인공지능, 빅데이터 |
| **안세희** | 인공지능전공 | 인공지능, 알고리즘, 게임 |
| **오디나버누** | 인공지능전공 | 웹 디자인, 테니스 |

### 팀 슬로건

"함께 미래를 설계하는 인공지능 학도"

### 팀 소개

저희는 인공지능이라는 하나의 목표를 가지고 우연히 모이게 된 인공지능 학도들입니다.
유레카 프로젝트 수업을 하면서 단순히 결과를 내는 것에 그치지 않고, 
누구도 쉽게 예상하지 못할 만큼 압도적으로 놀라운 성과를 보여주기 위해 저희 팀 모두 최선을 다해 노력할 준비가 되어 있습니다.

***

## 2️⃣ 공통된 관심사 : 백엔드, 인공지능

***

## 3️⃣ 한학기 동안의 활동 내역 

- 기관/부서 인터뷰 ✔️  

- 현장 탐방 ✔️  

- 멘토링 ✔️  
  - 내 지도 교수 함게 만나기
  - 대학원 방문 및 선배 만나기

- 프로젝트 진행 ✔️  
  - 과거에 사람들이 상상한 미래
  - 그들이 만들어가는 세상
  - 우리가 상상한 미래
  - 우리가 그리는 미래 그리고 나

- 각오와 소감 나누기 ✔️  


<!-- 활동 사진 추가 예시 -->
<img src="https://pixnio.com/free-images/2017/08/14/2017-08-14-13-09-09-960x651.jpg?text=활동사진1" width="330" height="190"/>
<img src="https://pixnio.com/free-images/2017/08/14/2017-08-14-20-51-02-960x640.jpg?text=활동사진2" width="330" height="190"/>
<img src="https://pixnio.com/free-images/2017/08/15/2017-08-15-10-05-39-960x640.jpg?text=활동사진3" width="330" height="190"/>

***
![11조 유레카 ](https://github.com/user-attachments/assets/370e1bd5-7a0a-412a-ab29-59100c1b519a)

## 4️⃣ 인상 깊은 활동

- 활동명 – 활동에 대한 간단한 설명과 배운 점을 작성  
- 예: 멘토링에서 실리콘밸리 현업 경험을 들을 수 있어 진로 방향 설정에 큰 도움이 되었다.  

***

## 5️⃣ 특별히 알아보고 싶은 것
- 예: 현장실습 제도
- 예: TOPCIT 정기평가
- 예: 졸업 후 진로(대학원/취업)

***

## 6️⃣ 활동을 마친 소감

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."


## Markdown을 사용하여 내용꾸미기를 익히세요.

Markdown은 작문을 스타일링하기위한 가볍고 사용하기 쉬운 구문입니다. 여기에는 다음을위한 규칙이 포함됩니다.

```markdown
과거에 사람들이 상상한 미래

삼섬페이, 에플페이, 모바일 교통카드, 삼성 서클 투 서치, 네이버 렌즈, 테블릿의 상용화, 원격 수업, 전기자동차, 자동차 내부 터치스크린 디스플레이, 스마트 미러, 사이버 가수 -> 버츄얼, 자율 주 행, 터치 테이블 상용화, 무빙워크, 주택 태양열, 로봇 청소기, AI 비서, VR

-느낀점

처음엔 과거 사람들이 상상했던 것들이 지금 현실에서 이루어졌다는 사실이 단순히 신기하게만 느껴졌습니다. 하지만 곰곰이 생각해 보면, 그 상상들은 단순한 공상이 아니라 미래를 열어가는 중요한 출발점이었습니다. 실제로 한때 전혀 평범하지 않았던 기술들이 오늘날 우리는 과학의 발전 속에서 너무도 당연하게 접하고 있습니다.

예를 들어, 2011년 Microsoft 비전 영상 속 클라우드 협업, 태블릿, 실시간 번역은 이미 일상이 되었고, 가상현실이나 로봇도 VR 기기나 청소 로봇을 통해 쉽게 경험할 수 있습니다. 또 로봇청소기, 원격 수업, 자율주행차처럼 과거의 상상이던 것들도 지금은 현실이 되었습니다. 물론 하늘을 나는 자동차 같은 기술은 아직 멀게 느껴지지만, 가능성은 분명히 남아 있습니다.

이처럼 불가능해 보였던 상상이 현실이 된 과정을 떠올리면, 지금 우리가 품고 있는 미래 역시 언젠가 현실로 다가올 수 있다는 생각이 듭니다. 기술은 단순한 편의성을 넘어 사회 전반에 변화를 일으키고 새로운 과제를 던지기도 하기에, 우리는 단순히 지켜보는 데 그치지 않고 미래를 어떻게 맞이할지 끊임없이 탐구하고 상상하는 태도가 필요하다고 느꼈습니다.


 TEDx – MIT Sixth Sense Project 를 듣고,

◆MIT Sixth Sense 연구팀이 만들고자 했던 것은?
• Why?
MIT Sixth Sense 연구팀은 사람들이 현실 세계와 디지털 세계를 동시에 살아가지만, 이 두 세계가 분리되어 있어 불편하다고 보았습니다. 컴퓨터를 사용하려면 반드시 키보드, 마우스, 모니터 같은 도구를 거쳐야 했고, 이는 일상적인 상황에서 직관적이지 않았습니다. 그래서 연구팀은 현실 세계 자체가 곧 디지털 정보와 연결되는 인터페이스가 된다면, 사람들이 훨씬 더 자연스럽게 정보를 접근하고 활용할 수 있을 것이라 생각하였고, 물리적 세계와 디지털 정보 세계 사이의 격차를 해소하고, 보다 자연스럽고 직관적인 방식으로 정보에 접근할 수 있도록 하고자 했습니다.
• What?
연구팀이 만들고자 했던 것은 ‘Sixth Sense(여섯 번째 감각)’라 불리는 착용형 인터페이스였습니다. 이는 인간의 다섯 감각을 넘어, 현실과 디지털 정보를 매끄럽게 융합해주는 새로운 감각을 의미합니다. 사용자는 손동작이나 주변 사물을 통해 디지털 정보를 불러오고, 현실 표면 위에 정보를 바로 투사해 활용할 수 있었습니다.
• How?
이를 구현하기 위해 연구팀은 소형 프로젝터, 카메라, 스마트폰을 조합한 장치를 고안했습니다. 프로젝터는 책, 벽, 손바닥과 같은 현실 표면에 디지털 정보를 직접 비추었고, 카메라는 손동작과 사물을 인식해 사용자의 의도를 파악했습니다. 스마트폰은 전체 시스템의 연산과 인터넷 연결을 담당했습니다. 또한 컴퓨터 비전과 제스처 인식 기술을 적용해 손가락 네 개로 사진을 찍거나, 책 표지를 인식해 온라인 리뷰를 보여주고, 손바닥 위에 시계를 투사하는 등 직관적인 상호작용을 가능하게 했습니다.
◆ As-Is vs To-Be는 어떻게?
기존 컴퓨터의 입력, 출력 장치를 어떠한 방식으로 변경하였나요??
• 키보드는?
키보드를 물리적 장치에서 가상, 투사형 입력 인터페이스로 바꿨다.
기존 키보드에서, 손가락 움직임과 프로젝션 기술을 이용해 어디서든 키보드를 만들어내는 방식으로 변경하려 했다. 
즉, 카메라가 손가락 끝의 움직임을 인식하고 프로젝터가 책상이나 벽, 손바닥 같은 표면 위에 가상 키보드를 투사하면 사용자가 그것을 실제 키보드처럼 두드려 입력할 수 있도록 하였다.
• 마우스는?
원래 마우스는 직접 물리적인 압력을 가해 작동 했다면, 이는  카메라를 이용하여, 손가락에 특정 색의 골무 같은 것을 착용하여 직접 손동작, 제스쳐를 이용하여 컴퓨터가 이를 인식하여 실시간으로 화면에 반영함.
• 모니터는?
원래 모니터는 물리적 도구를 통해 고정된 곳에서 화면을 띄우는 물리적 디스플레이를 필요로 했지만,여기서는  프로젝터를 이용하여 어디에서든 디스플레이 화면을 띄우는 것을 가능케 하였음.

◆ MIT Sixth Sense Project 팀이 만든 내용이 현재에는 어떠한 장비로, 어떻게 구현이 되었을까?
• 현재의 기술과 약 15년 전에 MIT에서 진행한 기술의 발전 모습은?
MIT의 SixthSense 프로젝트(2009)는 목걸이형 장치에 카메라 + 프로젝터를 달아 손가락 제스처나 종이·벽 같은 표면을 인터페이스로 사용하는 실험이었습니다. 당시에는 컬러 마커를 붙여 손동작을 추적하고, 프로젝터로 화면을 비추는 방식이라 휴대성·밝기·정확도에 한계가 있었습니다.
현재는 이 아이디어가 Apple Vision Pro, Meta Quest 3, Microsoft HoloLens 같은 혼합현실(MR) 헤드셋으로 발전했습니다. 이 장비들은 여러 대의 카메라, LiDAR, 손·눈 추적 기술을 활용해 현실 공간을 3D로 인식하고, 화면을 직접 눈앞에 겹쳐 보여주기 때문에 훨씬 몰입감 있고 정밀한 조작이 가능합니다.
또한 스마트폰 AR 기술(예: iPhone의 ARKit, Android의 ARCore)은 휴대폰 카메라와 센서를 이용해 테이블이나 벽 같은 평면을 인식하고 가상 물체를 배치할 수 있게 해줍니다. 이는 과거 SixthSense가 원하던 “현실 위에 디지털 정보 결합”을 대중이 손쉽게 경험할 수 있도록 만든 진화형 버전이라고 볼 수 있습니다.
결론적으로, SixthSense가 보여준 비전은 지금 프로젝터 기반 실험 → 헤드셋 기반 공간 컴퓨팅 + 스마트폰 AR이라는 형태로 이어지고 있습니다. 즉, 아이디어는 같지만 기술적 제약을 극복한 덕분에 산업 교육, 디자인, 원격 협업, 심지어 일반 소비자 경험까지 폭넓게 활용되는 수준으로 성숙했습니다.
<img width="1536" height="1024" alt="ChatGPT Image 2025년 10월 10일 오후 04_01_23" src="https://github.com/user-attachments/assets/23905b38-a288-469d-903a-27e53688cc23" />

```

자세한 내용은 [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Support or Contact

readme 파일 생성에 추가적인 도움이 필요하면 [도움말](https://help.github.com/articles/about-readmes/) 이나 [contact support](https://github.com/contact) 을 이용하세요.


